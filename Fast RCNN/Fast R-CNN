# Fast R-CNN

Created At: 2021ë…„ 7ì›” 29ì¼ ì˜¤ì „ 1:49
Created By: ì¡°ìŠ¹ì œ
Topics: Deep Learning, Object Detection
Type: ğŸ“’ Lesson
ë°œí‘œì¼: 2021ë…„ 7ì›” 29ì¼
ë°œí‘œì: ì¡°ìŠ¹ì œ
ì°¸ì„ì: ì¡°ê±´ìš°, ìµœì†Œì€, ìœ ì •ë¯¼, ì—„í˜„ì‹

## 1. Introduction

- R-CNNê³¼ SPP-Netì˜ ë‹¨ì ì„ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì œì•ˆë¨
- R-CNN ë‹¨ì 
    1. Training is a multi-stage pipeline
    2. Training is expensive in space and time
        1. For SVM and bounding-box regressor training, features are extracted from each object proposal in each image and written to disk.
    3. Object detection is slow
        1. Detection with VGG16 takes 47s / image (on a GPU).
- SPP-Net ë‹¨ì 
    1. SPP-Netì—ì„œëŠ” (4x4, 2x2, 1x1)ì˜ spatial binì„ ì´ìš©í•˜ë©´ ë‹¤ì–‘í•œ resolutionì„ í•™ìŠµí•˜ê²Œ ë˜ëŠ” ì¥ì ì´ ìˆë‹¤ê³  ì„¤ëª…
    2. í•˜ì§€ë§Œ í•˜ë‚˜ì˜ ê°ì²´ì— ëŒ€í•´ì„œ ë‹¤ì–‘í•œ resolutionì„ í•™ìŠµí•˜ê²Œ ë˜ë©´ overfittingì´ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§
- Contributions

    We propose a new training algorithm that fixes the disadvantages of R-CNN and SPPnet, while improving on their speed and accuracy.

    1. Higher detection quality (mAP) than R-CNN, SPPnet
    2. Training is single-stage, using a multi-task loss
    3. Training can update all network layers
    4. No disk storage is required for feature caching

    Fast R-CNN is written in Python and C++ [github](https://github.com/rbgirshick/)

## 2. Fast R-CNN architecture and training

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled.png)

### 1) The RoI pooling layer

- region of interest into a small feature map with a fixed spatial extent of H Ã— W (e.g., 7 Ã— 7)
    - H and W are layer hyper-parameters
- RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (r, c, h, w) that specifies its top-left corner (r, c) and its height and width (h, w)
- The RoI layer is simply the special-case of the spatial pyramid pooling layer used in SPPnets in which there is only one pyramid level.

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/img.gif](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/img.gif)

### 2) Initializing from pre-trained networks

- 5ê°œì˜ max pooling layer, 5~13ê°œì˜ conv layersê°€ ìˆëŠ” ImageNetìœ¼ë¡œ Pre-trainedëœ ëª¨ë¸ 3ê°œë¡œ Fast R-CNNì˜ CNNì„ initializesí•´ì„œ ë¹„êµ
- Pre-trained networkëŠ” 3ê°€ì§€ ë³€í™˜ì„ ê±°ì¹¨
    1. ë§ˆì§€ë§‰ max pooling layerëŠ” FC layerì™€ í˜¸í™˜ë˜ë„ë¡ H, Wê°’ì„ ì„¤ì •í•œ RoI Pooling layerë¡œ ëŒ€ì²´
    2. Pre-trained networkì˜ ë§ˆì§€ë§‰ FC layerì™€ softmaxëŠ” ìœ„ì—ì„œ ì–¸ê¸‰í•œ ì„œë¡œ ë‹¤ë¥¸ ë ˆì´ì–´ 2ê°œë¡œ ëŒ€ì²´
    3. 2ê°€ì§€ Inputì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ìˆ˜ì • (Image, list of Rols)

### 3) Fine-tuning for detection

1. Hierarchical Sampling
    1. R-CNNì—ì„œëŠ” ì—¬ëŸ¬ ì¥ì˜ ì´ë¯¸ì§€ì—ì„œ ëœë¤í•˜ê²Œ Nê°œì˜ ì˜ì—­ì„ ìƒ˜í”Œë§í•œ mini-batchë¥¼ êµ¬ì„±í•˜ì—¬ í•™ìŠµ
    2. Fast R-CNNì—ì„œëŠ” 1ì¥ ë˜ëŠ” 2ì¥(N)ì˜ ì´ë¯¸ì§€ì—ì„œ Rê°œì˜ ì˜ì—­ì„ ìƒ˜í”Œë§í•œ mini-batchë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì— í•„ìš”í•œ CNN ì—°ì‚°ëŸ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¤„ì„
    3. ë…¼ë¬¸ì—ì„  Nì€ 2, Rì€ 128 ì‚¬ìš©
2. Multi-task loss
    1. two sibling output layersë¥¼ ê°€ì§ (classification, bounding-box regression)
    2. L1 distanceë¥¼ ê³„ì‚°í•˜ëŠ” ì´ìœ ëŠ” L2 distanceë¥¼ ê³„ì‚°í•  ì‹œ gradientê°€ explode ë˜ëŠ” í˜„ìƒì„ ê´€ì°°í–ˆê¸° ë•Œë¬¸

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%201.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%201.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%202.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%202.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%203.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%203.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%204.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%204.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%205.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%205.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%206.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%206.png)

u:  fully-connacted   ì •ë‹µ ë²¡í„°  ë°°ê²½ 0 ì€ ì œì™¸í•˜ê³  ê³„ì‚°í•œë‹¤ 

v : bounding box ì •ë‹µ ê°’

The hyper-parameter Î» in Eq. 1 controls the balance between the two task losses

(Î» = 1ë¡œ ì‹¤í—˜)

### 4) Mini-batch sampling

- N=2, R=128 â†’ sampling 64 RoIs from each image
- mini-batchì˜ 25%ëŠ” IoUê°’ì´ 0.5 ì´ìƒì¸ RoIs, ë‚˜ë¨¸ì§€ 75%ëŠ” IoUê°’ì´ 0.1~0.5ì˜ RoIs
- í•™ìŠµ ê³¼ì •ì—ì„œ 50% í™•ë¥ ë¡œ Horizontal flip

### 5) Back-propagation through RoI pooling layer

- ì´ì „ R-CNN, SPP Netì€ ê° Task ë³„ë¡œ fine-tuningì„ ì§„í–‰í–ˆëŠ”ë°, ì´ëŠ” ì„±ëŠ¥ í–¥ìƒì— ì œì•½ì´ ìˆë‹¤ê³  ì£¼ì¥
- RoI Pooling Layer ì´ì „ê¹Œì§€ back-propagationì´ ê°€ëŠ¥í•œ ê²ƒì¸ì§€ ê²€ì¦

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%207.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%207.png)

Let xi âˆˆ R be the i-th activation input into the RoI pooling layer

Let yrj be the layerâ€™s j-th output from the r-th RoI

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%208.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%208.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%209.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%209.png)

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2010.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2010.png)

## 3. Main results

1. State-of-the-art mAP on VOC07, 2010, and 2012
2. Fast training and testing compared to R-CNN, SPPnet
3. Fine-tuning conv layers in VGG16 improves mAP

## 4. Experiments

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2011.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2011.png)

- ëª¨ë¸ í¬ê¸° ë³„ ì‹¤í—˜
    - S = CaffeNet (essentially AlexNet)
    - M = VGG_CNN_M_1024
    - L = VGG16

    ![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2012.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2012.png)

- SVM vs Softmax

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2013.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2013.png)

- Speed Up

![Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2014.png](Fast%20R-CNN%206c77f95378934f4885809bf32b544035/Untitled%2014.png)

## 5. Conclusion

- R-CNN, SPP-Netì— ë¹„í•´ ë›°ì–´ë‚œ ì„±ëŠ¥
- multi-task loss ì‚¬ìš©ìœ¼ë¡œ single-stage trainingì´ ê°€ëŠ¥í•´ì§
- Test timeì´ ë§¤ìš° ë‹¨ì¶•ë¨
    - í•˜ì§€ë§Œ ì´ë¯¸ì§€ 1ì¥ ë‹¹ 2.3ì´ˆì˜ ì‹œê°„ì´ ì†Œìš”ë˜ë¯€ë¡œ ì‹¤ì‹œê°„ íƒì§€ì—ëŠ” ì—­ë¶€ì¡±
    - Region Proposalì— 2.3ì´ˆ ì¤‘ 2ì´ˆê°€ ê±¸ë¦¼